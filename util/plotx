#!/usr/bin/env python3
#!/usr/bin/env python3
"""
Usage:
    plot-parquet2 EXPRESSION [EXPRESSION ...]

Description:
    This tool plots time-series data from Parquet or CSV files. Each EXPRESSION can include file column references
    and constants, and the arithmetic expression is evaluated to produce a Pandas Series which is then plotted
    against its index. Multiple expressions provided on the command line will be plotted in separate subplots,
    while comma-separated expressions within a single argument will be plotted on the same subplot.

Token Formats:
    1. Multi-level column reference:
         "filename:col:field"
         - Loads "filename.parquet" or "filename.csv" and extracts the multi-level column (col, field).

    2. Single-level column reference:
         "filename:column"
         - Loads "filename.parquet" or "filename.csv" and extracts the column "column".

    3. Constant:
         ":number"
         - Interprets as a constant number.

Examples:
    1. Plot a single multi-level column (from a Parquet file):
         plot-parquet2 2025-02-20:NVDA:close

    2. Plot a single-level column (from a CSV or Parquet file):
         plot-parquet2 NVDA:close

    3. Plot an arithmetic expression between a multi-level and a single-level column:
         plot-parquet2 2025-02-20:NVDA:close / NVDA:close

    4. Plot an expression using a constant:
         plot-parquet2 NVDA:close / :2.4

    5. Plot multiple expressions on the same subplot:
         plot-parquet2 "NVDA:close, 2025-02-20:NVDA:close"

    6. Plot each expression in separate subplots:
         plot-parquet2 "NVDA:close" "2025-02-20:NVDA:close"

Note:
    - The file token (e.g. "NVDA" or "2025-02-20") will be resolved by checking for "NVDA.parquet" (or "2025-02-20.parquet")
      first. If not found, it will try "NVDA.csv" (or "2025-02-20.csv").
    - For CSV files, a heuristic is applied to identify a datetime column. If a columnâ€™s first few entries can be parsed as dates,
      that column is set as the index and used for the x-axis labels.
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import re
import argparse

def infer_datetime_index(df, nrows=5):
    """
    Heuristic to detect a datetime column in a DataFrame.
    If a column has object/string data and at least half of its first nrows can be parsed as dates,
    then set that column as the index.
    """
    for col in df.columns:
        # If already datetime, use it.
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            return df.set_index(col)
        # Otherwise, if the column is object-like, try to convert a few entries.
        if df[col].dtype == 'object':
            sample = pd.to_datetime(df[col].head(nrows), errors='coerce')
            if sample.notna().sum() >= max(1, nrows // 2):
                return df.set_index(col)
    return df

def load_data(file_name_base):
    """
    Attempt to load a file from a given base name.
    Try {file_name_base}.parquet first; if that fails, try {file_name_base}.csv.
    For CSV files, apply a heuristic to detect a datetime column.

    Returns:
        A tuple (df, actual_file) where actual_file is the filename used.
    """
    file_candidates = [f"{file_name_base}.parquet", f"{file_name_base}.csv"]
    for candidate in file_candidates:
        if os.path.exists(candidate):
            if candidate.endswith(".parquet"):
                df = pd.read_parquet(candidate)
            elif candidate.endswith(".csv"):
                df = pd.read_csv(candidate)
                df = infer_datetime_index(df)
            return df, candidate
    raise FileNotFoundError(f"Neither {file_name_base}.parquet nor {file_name_base}.csv exists.")

def evaluate_new_expression(expression, file_cache=None):
    """
    Evaluate an arithmetic expression supporting tokens in the new format.

    Supported token formats:
      - Multi-level column reference:
          "filename:col:field"
          Loads "filename.parquet" or "filename.csv" and extracts the multi-level column (col, field).
      - Single-level column reference:
          "filename:column"
          Loads "filename.parquet" or "filename.csv" and extracts the column "column".
      - Constant:
          ":number"
          Interprets as a constant number.

    Example:
         "2025-02-20:NVDA:close / NVDA:close"
    """
    if file_cache is None:
        file_cache = {}
    local_vars = {}
    token_to_var = {}
    safe_expr = expression

    # Regex pattern supports tokens of two forms:
    #   1. File tokens: either "file:col" (single-level) or "file:col:field" (multi-level)
    #   2. Constant tokens: tokens starting with a colon followed by a number.
    pattern = re.compile(
        r'(?P<file_token>(?P<file>[^:\s]+):(?P<col>[^:\s]+)(?::(?P<field>[^:\s]+))?)'
        r'|(?P<constant_token>:(?P<constant>-?\d+(?:\.\d+)?))'
    )

    for match in pattern.finditer(expression):
        token = match.group(0)
        if token in token_to_var:
            continue
        safe_var = f"token_{len(token_to_var)}"
        token_to_var[token] = safe_var

        if match.group('constant_token'):
            try:
                const_value = float(match.group('constant'))
                local_vars[safe_var] = const_value
            except ValueError:
                print(f"Error parsing constant token '{token}'.")
                local_vars[safe_var] = 0.0
        elif match.group('file_token'):
            file_name = match.group('file')
            try:
                df, actual_file = load_data(file_name)
            except FileNotFoundError as e:
                print(e)
                local_vars[safe_var] = pd.Series(dtype=float)
                continue
            if actual_file not in file_cache:
                file_cache[actual_file] = df
            df = file_cache[actual_file]

            col_name = match.group('col')
            field_name = match.group('field')  # None for single-level tokens

            if field_name is not None:
                # Multi-level column: expect df.columns to be a MultiIndex.
                if isinstance(df.columns, pd.MultiIndex):
                    key = (col_name, field_name)
                    if key in df.columns:
                        local_vars[safe_var] = df[key]
                    else:
                        print(f"Warning: Column {key} not found in {actual_file}.")
                        local_vars[safe_var] = pd.Series(dtype=float)
                else:
                    # If not MultiIndex, try a composite key (e.g. "col:field")
                    key = f"{col_name}:{field_name}"
                    if key in df.columns:
                        local_vars[safe_var] = df[key]
                    else:
                        print(f"Warning: Column {key} not found in {actual_file}.")
                        local_vars[safe_var] = pd.Series(dtype=float)
            else:
                # Single-level column: expect df.columns to be a single index.
                if not isinstance(df.columns, pd.MultiIndex):
                    if col_name in df.columns:
                        local_vars[safe_var] = df[col_name]
                    else:
                        print(f"Warning: Column '{col_name}' not found in {actual_file}.")
                        local_vars[safe_var] = pd.Series(dtype=float)
                else:
                    # If the DataFrame has a MultiIndex but only two parts were provided,
                    # warn the user and try to use the first matching column.
                    print(f"Warning: File {actual_file} has a MultiIndex; token '{token}' may be ambiguous.")
                    possible = [col for col in df.columns if col[0] == col_name]
                    if possible:
                        local_vars[safe_var] = df[possible[0]]
                    else:
                        local_vars[safe_var] = pd.Series(dtype=float)
        safe_expr = safe_expr.replace(token, safe_var)

    try:
        result = eval(safe_expr, {"np": np}, local_vars)
        if not isinstance(result, (pd.Series, pd.DataFrame)):
            print(f"Error: Expression '{expression}' did not result in a Pandas Series.")
            return None
        return result
    except Exception as e:
        print(f"Error evaluating expression '{expression}': {e}")
        return None

def plot_columns(group_expressions):
    """
    For each group expression (which may contain comma-separated subexpressions),
    evaluate each subexpression (using the new format) and plot them on the same subplot.
    If any of the series has a datetime index, the x-axis will be formatted accordingly.
    """
    num_groups = len(group_expressions)
    fig, axes = plt.subplots(num_groups, 1, figsize=(10, 5 * num_groups), sharex=True)
    if num_groups == 1:
        axes = [axes]

    file_cache = {}

    for ax, group_expr in zip(axes, group_expressions):
        sub_expressions = [s.strip() for s in group_expr.split(",") if s.strip()]
        series_list = []

        for sub_expr in sub_expressions:
            series = evaluate_new_expression(sub_expr, file_cache)
            if series is None or (isinstance(series, pd.Series) and series.dropna().empty):
                print(f"Skipping subexpression '{sub_expr}' due to errors or no valid data.")
                continue
            if isinstance(series, pd.Series):
                series = series.dropna()
            series_list.append(series)
            ax.plot(series.index, series, label=sub_expr)

        if not series_list:
            print(f"No valid data to plot for group '{group_expr}'.")
            continue

        # If any series index is datetime, format the x-axis as dates.
        if any(pd.api.types.is_datetime64_any_dtype(s.index) for s in series_list):
            ax.xaxis_date()

        combined_values = np.concatenate([s.values for s in series_list if not s.empty])
        y_min, y_max = np.percentile(combined_values, [2, 98])
        y_min -= (y_max - y_min) * 0.1
        y_max += (y_max - y_min) * 0.1
        ax.set_ylim(y_min, y_max)
        ax.set_ylabel(group_expr)
        ax.legend()
        ax.grid(True)

    # Auto-format date labels on the x-axis for the entire figure.
    plt.gcf().autofmt_xdate()
    plt.xlabel("Time")
    plt.tight_layout()
    plt.show()

def main():
    parser = argparse.ArgumentParser(
        description=("Plot expressions from Parquet or CSV files supporting both single and multi-level columns. "
                     "Token formats: 'filename:col:field' for multi-level and 'filename:column' for single-level. "
                     "Constants are specified as ':number'. For CSV files, a heuristic is used to detect a datetime "
                     "column from the first few data points to use as the x-axis labels.")
    )
    parser.add_argument("expressions", type=str, nargs='+',
                        help=('List of expressions. For file column references use "filename:col:field" (multi-level) '
                              'or "filename:column" (single-level), and for constants use ":number".'))
    args = parser.parse_args()
    plot_columns(args.expressions)

if __name__ == "__main__":
    main()

