#!/usr/bin/env python3

# plot time series parquets with math
#
# assumption is the index is a timestamp and there are various columns you want to plot
#
# $ plot-parquet /fin/matrix/2025-02-14.parquet "NVDA.close" "NVDA.C_volume / NVDA.P_volume"
# will have two subplots, one with NVDA.close and one with NVDA.C_volume/NVDA.P_volume
#
# you can put two into the same plot with a comma separator e.g.
# $ plot-parquet /fin/matrix/2025-02-14.parquet "NVDA.open, NVDA.close" "NVDA.volume"
# will put open and close into the same plot

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import re
import argparse
import keyword

def load_parquet(file_path):
    """Load a Parquet file into a DataFrame."""
    return pd.read_parquet(file_path)

def find_multiindex_references(expression, df):
    """
    Finds tokens like 'SOMENAME.SOMEFIELD' in the expression.
    If df.columns is a MultiIndex, it checks for the tuple (SOMENAME, SOMEFIELD).
    If df.columns is a single index, it checks for the full string token.
    Maps found tokens to safe Python variable names.
    """
    # Pattern: first part must start with a letter/underscore
    pattern = re.compile(r'\b([A-Za-z_][A-Za-z0-9_]*)\.([A-Za-z_][A-Za-z0-9_]*)\b')
    token_to_var = {}
    local_dict = {}

    for match in pattern.finditer(expression):
        original_str = match.group(0)  # e.g. "NVDA.close"
        if original_str in token_to_var:
            continue
        sym = match.group(1)
        field = match.group(2)
        safe_var = f"col_{len(token_to_var)}"

        if isinstance(df.columns, pd.MultiIndex):
            col_tuple = (sym, field)
            if col_tuple not in df.columns:
                print(f"Warning: Column '{original_str}' not found in DataFrame.")
                token_to_var[original_str] = f"__invalid_{len(token_to_var)}"
                local_dict[token_to_var[original_str]] = pd.Series(dtype=float)
                continue
            local_dict[safe_var] = df[col_tuple]
        else:
            # Single-index columns: look for the whole token as a column name
            if original_str not in df.columns:
                print(f"Warning: Column '{original_str}' not found in DataFrame.")
                token_to_var[original_str] = f"__invalid_{len(token_to_var)}"
                local_dict[token_to_var[original_str]] = pd.Series(dtype=float)
                continue
            local_dict[safe_var] = df[original_str]

        token_to_var[original_str] = safe_var

    return token_to_var, local_dict

def find_singleindex_references(expression, df, token_to_var, local_dict):
    """
    For single-index DataFrames, if no tokens were found by the multiindex pattern,
    look for valid Python identifiers in the expression that exist as column names.
    """
    # Only apply if columns are single-index.
    if isinstance(df.columns, pd.MultiIndex):
        return token_to_var, local_dict

    # Get all candidate tokens (valid Python identifiers)
    candidates = re.findall(r'\b[A-Za-z_][A-Za-z0-9_]*\b', expression)
    # Exclude some reserved words and known names
    reserved = set(keyword.kwlist) | {"np"}
    for token in candidates:
        if token in reserved:
            continue
        if token in token_to_var:
            continue  # already processed via multiindex lookup
        if token in df.columns:
            safe_var = f"col_{len(token_to_var)}"
            token_to_var[token] = safe_var
            local_dict[safe_var] = df[token]
    return token_to_var, local_dict

def transform_expression(expression, token_to_var):
    """Replace each token in the expression with its safe variable name."""
    for original, safe_var in token_to_var.items():
        expression = re.sub(rf'\b{re.escape(original)}\b', safe_var, expression)
    return expression

def evaluate_expression(expression, df):
    """
    Evaluate an expression by:
      1. Finding column references.
      2. Replacing them with safe variable names.
      3. Evaluating the expression.
    """
    # First, try to find multiindex-style tokens.
    token_to_var, local_dict = find_multiindex_references(expression, df)
    # For single-index DataFrames, also check for simple token names.
    token_to_var, local_dict = find_singleindex_references(expression, df, token_to_var, local_dict)
    safe_expression = transform_expression(expression, token_to_var)
    try:
        out_series = eval(safe_expression, {"np": np}, local_dict)
    except Exception as e:
        print(f"Error evaluating expression '{expression}': {e}")
        return None

    if not isinstance(out_series, (pd.Series, pd.DataFrame)):
        print(f"Error: Expression '{expression}' did not result in a Pandas Series.")
        return None

    return out_series

def plot_columns(df, group_expressions):
    """
    For each group expression (which may contain comma-separated subexpressions),
    evaluate each subexpression and plot them on the same subplot.
    """
    num_groups = len(group_expressions)
    fig, axes = plt.subplots(num_groups, 1, figsize=(10, 5 * num_groups), sharex=True)
    if num_groups == 1:
        axes = [axes]

    for ax, group_expr in zip(axes, group_expressions):
        # Split the group expression by comma (if any) and strip whitespace
        sub_expressions = [s.strip() for s in group_expr.split(",") if s.strip()]
        series_list = []

        for sub_expr in sub_expressions:
            series = evaluate_expression(sub_expr, df)
            if series is None or series.dropna().empty:
                print(f"Skipping subexpression '{sub_expr}' due to errors or no valid data.")
                continue
            series = series.dropna()
            series_list.append(series)
            ax.plot(series.index, series, label=sub_expr)

        if not series_list:
            print(f"No valid data to plot for group '{group_expr}'.")
            continue

        # Combine all valid series values to compute unified y-axis bounds
        combined_values = np.concatenate([s.values for s in series_list if not s.empty])
        y_min, y_max = np.percentile(combined_values, [2, 98])
        y_min -= (y_max - y_min) * 0.1
        y_max += (y_max - y_min) * 0.1
        ax.set_ylim(y_min, y_max)
        ax.set_ylabel(group_expr)
        ax.legend()
        ax.grid(True)

    plt.xlabel("Time")
    plt.tight_layout()
    plt.show()

def main():
    parser = argparse.ArgumentParser(
        description=("Plot specified columns or expressions from a Parquet file against its index. "
                     "If a comma-separated list is provided, those expressions are plotted on the same pane.")
    )
    parser.add_argument("file", type=str, help="Path to the Parquet file.")
    parser.add_argument("expressions", type=str, nargs='+',
                        help=('List of column names or expressions (e.g., "MSTR.close / BITX.close / 6.2", '
                              '"NVDA.bid, NVDA.close", or "NVDA.volume * 10").'))

    args = parser.parse_args()
    df = load_parquet(args.file)
    plot_columns(df, args.expressions)

if __name__ == "__main__":
    main()

